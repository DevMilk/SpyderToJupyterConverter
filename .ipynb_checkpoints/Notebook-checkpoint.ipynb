{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug  5 09:29:08 2020\n",
    "\n",
    "@author: Ugur\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sb\n",
    "\n",
    "figDir = \"Figures/\"     \n",
    "\n",
    "\n",
    "df = pd.read_json('syntetic-nd.json', lines = True)    \n",
    "df = df.set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing aand Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing, Data preperation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def split(): print(\"\\n____________________________________________________________________________________\\n\")\n",
    "\n",
    "#Tüm featureler için korelasyon matrisi\n",
    "# Correlation matrix for all features\n",
    "def plotCorrelationMatrix(df, graphWidth,save=False):  \n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix for xd', fontsize=40)\n",
    "    plt.show()\n",
    "#Boxplot, gruplama ve korelasyonların hepsini analiz eden all-in-one fonksiyon\n",
    "# ALL-IN-ONE function for data analysis\n",
    "\n",
    "    if(save):\n",
    "        plt.savefig(figDir+'CorrelationMatrix.png')\n",
    "def intro(df,graph=True,splitPlots=True,EraseNullColumns=False,printCorrelations=True,corrThreshold=0.5,save=False):\n",
    "    \n",
    "    dataframe=df.copy()\n",
    "    \n",
    "    if(EraseNullColumns==True):  dataframe.dropna(axis=1,inplace=True)\n",
    "\n",
    "    split()\n",
    "    print(df)\n",
    "    split()\n",
    "    print(dataframe.head(5))\n",
    "    split()\n",
    "    \n",
    "    print(dataframe.info())\n",
    "    split()\n",
    "    \n",
    "    print(dataframe.describe())\n",
    "    split()\n",
    "    \n",
    "#-------------------------------BOXPLOTFEATURES-----------------------------      \n",
    "    \n",
    "    \n",
    "    if(graph):\n",
    "\n",
    "        if(splitPlots==True):\n",
    "            print(\"                         ___BOXPLOTFETURES\")\n",
    "\n",
    "            for column in dataframe.columns:\n",
    "                if(dataframe[column].dtype==np.int or dataframe[column].dtype==np.float):\n",
    "                    plt.figure()\n",
    "                    dataframe.boxplot([column])\n",
    "                    if(save):\n",
    "                        plt.savefig(figDir+'{}.png'.format(column))\n",
    "                    \n",
    "        else:\n",
    "            dataframe.boxplot()\n",
    "            \n",
    "    #If unique values of columns is under 10, print unique values with considered column\n",
    "\n",
    "\n",
    "#-------------------------------GROUPBY-----------------------------        \n",
    "\n",
    "    print(\"                         _____GROUPBY____\")\n",
    "\n",
    "    for column in dataframe.columns:    \n",
    "        unique_values=dataframe[column].unique()\n",
    "        if(unique_values.size<=10):\n",
    "            print(column,\": \",unique_values)\n",
    "            print(\"\\nGrouped By: \",column,\"\\n\\n\",dataframe.groupby(column).mean())\n",
    "            split()\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        \n",
    "#-------------------------------CORRELATIONS-----------------------------        \n",
    "    if(printCorrelations==True):\n",
    "        print(\"                         ____CORRELATIONS____\")\n",
    "        corrByValues= dataframe.corr().copy()\n",
    "        flag = False\n",
    "        corr_matrix=abs(corrByValues>=corrThreshold)\n",
    "        columns= corr_matrix.columns\n",
    "        for i in range(columns.size):\n",
    "            for j in range(i,columns.size):\n",
    "                iIndex=columns[i]\n",
    "                jIndex=columns[j] \n",
    "                if (i!=j and corr_matrix[iIndex][jIndex]==True and (len(df[iIndex].unique())!=1 and len(df[jIndex].unique())!=1 )):\n",
    "                    sign = \"Positive\"\n",
    "                    if(corrByValues[iIndex][jIndex]<0): sign=\"Negative\"\n",
    "                    split()\n",
    "                    flag = True\n",
    "                    print(iIndex.upper(), \" has a \" ,sign,\" correlation with \",jIndex.upper(),\": {} \\n\".format(corrByValues[iIndex][jIndex]))\n",
    "        \n",
    "        plt.show()\n",
    "        plotCorrelationMatrix(df,30)       \n",
    "        \n",
    "        split()\n",
    "        if(not flag):\n",
    "            print(\"No Correlation Found\") \n",
    "    return dataframe\n",
    "\n",
    "#KDE dağılımı ile featureları plotlar\n",
    "# KDE plot function that plots all features in given dataframe\n",
    "\n",
    "def plotCols(df,time,save=False):\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if(df[col].dtype==np.int or df[col].dtype==np.float):\n",
    "            if(len(df[col].unique())>1):\n",
    "                fig = df.plot(x=time,y=col,kind=\"kde\", title = \"{}-{} KDE\".format(time,col))   \n",
    "                if(save):\n",
    "                    fig.get_figure().savefig(figDir+\"{}-kde.png\".format(time+\"-\"+col))\n",
    "                plt.show()\n",
    "            plt.plot(df[time],df[col]) \n",
    "            plt.title(\"{}-{}\".format(time,col))\n",
    "            plt.show()\n",
    "            if(save):\n",
    "                plt.savefig(figDir+'{}.png'.format(time+\"-\"+col))\n",
    "        \n",
    "#Verilen feature'ları scatter ile Y'ye göre karşılaştırır.  \n",
    "#Function for comparing given features in dataframe with Y feature\n",
    "\n",
    "def XCorrWithY(df, X, Y):\n",
    "    for col in  X:\n",
    "        print(col,\"-\",Y)\n",
    "        plt.scatter(df[col],df[Y]) \n",
    "        plt.title(\"{}-{}\".format(col,Y))\n",
    "        plt.show()    \n",
    "#Dataframeyi normalize eder. (Preprocessing) \n",
    "#Normalizes dataframe\n",
    "\n",
    "def normalizedf(df,offset=0):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler() \n",
    "    new = df.copy()\n",
    "    cols = df.columns[offset:]\n",
    "    new[cols] = (min_max_scaler.fit_transform(new[cols]) )  \n",
    "    return new    \n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset.iloc[i:(i+look_back), :]\n",
    "\t\tdataX.append(a.to_numpy())\n",
    "\t\tdataY.append(dataset.iloc[i + look_back, -1]) \n",
    "\treturn np.array(dataX), np.array(dataY)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalizedf(df)\n",
    "\n",
    "X_f, Y_f = create_dataset(df.drop(columns=[\"Feature2\"]),17)\n",
    "#%% Visualize and Analyze dataframe\n",
    "intro(df)\n",
    "df.reset_index().plot(x=\"timestamp\",y=\"Feature1\" )\n",
    "df.reset_index().plot(x=\"timestamp\",y=\"Feature2\" )\n",
    "\n",
    "#Bir senörün anomlisi, diğer sensörden bağımsız. Anomalileri arasında ilişkileri yok.\n",
    "#2 Sensör arasında Korelasyonun 0.54 değerinde olması, frekanslarının aynı olmasından kaynaklanıyor olmalı"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Anomaly Detection Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM #Bu data üzerinde Başarılı Değil\n",
    "from sklearn.ensemble import IsolationForest  #Bu data üzerinde başarılı değil\n",
    "from sklearn.neighbors import LocalOutlierFactor \n",
    "from kenchi.outlier_detection.statistical import HBOS\n",
    "\n",
    "modelsNotFitted = [ LocalOutlierFactor(leaf_size=10 , novelty=False) ] \n",
    "X = X_f.reshape(X_f.shape[:-1]) \n",
    "#Anomali olup olmadığına bak\n",
    "for model in modelsNotFitted: \n",
    "    model.fit_predict(X) \n",
    "    lof = model.negative_outlier_factor_\n",
    "    plt.plot(lof/min(lof),color=\"orange\") \n",
    "    plt.title(\"LocalOutlierFactor On Feature 1\")\n",
    "    plt.plot(Y_f)\n",
    "    plt.show()      \n",
    "#LocalOutlierFactor başarılı    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LUMINOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminol import  anomaly_detector \n",
    "df = df.reset_index()\n",
    "df[\"timestamp\"] = (df[\"timestamp\"].astype('uint64') / 1e6).astype('uint32')\n",
    "df.set_index(\"timestamp\")\n",
    "a = df.drop(columns=[\"Feature2\"]).to_dict(\"series\")[\"Feature1\"].to_dict()\n",
    "detector = anomaly_detector.AnomalyDetector(a,algorithm_name=\"exp_avg_detector\",score_threshold = 0.2 ) \n",
    "anomalies = detector.get_anomalies() \n",
    " \n",
    "time_periods = [] \n",
    "values = []\n",
    "for key in (a): \n",
    "    time_periods.append(key)\n",
    "    values.append(a[key])\n",
    "plt.plot(time_periods,values)     \n",
    "       \n",
    "anom_times = []\n",
    "anom_values = []\n",
    "for anom in anomalies :  \n",
    "    anom_times.append(np.arange(anom.start_timestamp,anom.end_timestamp))\n",
    "    anom_values.append(anom.anomaly_score)\n",
    "    s, e = anom.start_timestamp, anom.end_timestamp\n",
    "    v = []\n",
    "    for i in range(s,e  ):\n",
    "        v.append(a[s])\n",
    "    timerange =  np.arange(s,e)   \n",
    "    plt.plot(timerange,v, c =\"r\",marker= 'o') \n",
    "plt.title(\"Luminol on Feature 1\")\n",
    "plt.show( )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Random Cut Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rrcf\n",
    "X = df[\"Feature1\"].tolist()\n",
    " \n",
    "TREE_COUNT = 100\n",
    "SHINGLE_COUNT = 8\n",
    "TREE_SIZE = 200\n",
    "forest = [] \n",
    "for i in range(TREE_COUNT):\n",
    "    tree = rrcf.RCTree()\n",
    "    forest.append(tree)\n",
    "points = rrcf.shingle(X, size=SHINGLE_COUNT)\n",
    "\n",
    "avg_codisp = {}\n",
    "\n",
    " \n",
    "for index, point in enumerate(points): \n",
    "    for tree in forest: \n",
    "        if len(tree.leaves) > TREE_SIZE:\n",
    "            tree.forget_point(index - TREE_SIZE) \n",
    "        tree.insert_point(point, index=index) \n",
    "        if not index in avg_codisp:\n",
    "            avg_codisp[index] = 0\n",
    "        avg_codisp[index] += tree.codisp(index) / TREE_COUNT\n",
    "        \n",
    "time_periods = [] \n",
    "values = []\n",
    "for key in avg_codisp:\n",
    "    time_periods.append(key)\n",
    "    values.append(avg_codisp[key])\n",
    "\n",
    "PLOTSCALE= 5    \n",
    "values = np.array(values)/(PLOTSCALE* max(values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Robust Random Cut Forest Algorithm on Feature 1\")\n",
    "\n",
    "sb.lineplot(time_periods,values,label=\"Anomaly Scores\"  )\n",
    "sb.lineplot(time_periods,X[SHINGLE_COUNT-1:],label=\"Values\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Autoencoder for Novelty Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, LSTM, Dropout, LeakyReLU  ,RepeatVector,TimeDistributed\n",
    "\n",
    "from keras.optimizers import Adam, SGD, Adamax,RMSprop  \n",
    "import tensorflow as tf \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# ilk 4000'de anomaly yok\n",
    "X_train,_ = create_dataset(df.drop(columns=\"Feature1\")[:4000],200)\n",
    "model = Sequential()\n",
    "model.add( LSTM(\n",
    "    units=64,\n",
    "    input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "))\n",
    "model.add(Dense(10 ))\n",
    "model.add( Dropout(rate=0.2))  \n",
    "model.add(Dense(64))\n",
    "model.add( Dropout(rate=0.2))\n",
    "model.add( Dense ( units = X_train.shape[1] ) ) \n",
    "          \n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "history = model.fit(\n",
    "    X_train, X_train.reshape( X_train.shape[:-1] ),\n",
    "    epochs=300,\n",
    "    batch_size=300,\n",
    "    validation_split=0.05,\n",
    "    shuffle=False,\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=0, mode='min'),\n",
    "                       ModelCheckpoint(\"AE1.h5\",monitor='val_loss', save_best_only=True, mode='min', verbose=1)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"AE1.h5\")  \n",
    "test,_ = create_dataset(df.drop(columns=\"Feature1\")[4000:] ,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Original and Reconstructed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"AutoEncoder on Feature 1\\nOriginal vs Reconstructed Values\")\n",
    "plt.plot(test.reshape(test.shape[:-1]),c=\"red\")  \n",
    "plt.plot(model.predict(test),c=\"orange\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(np.arange(len(history.history[\"loss\"])),history.history[\"loss\"], label=\"Loss\")\n",
    "sns.lineplot(np.arange(len(history.history[\"loss\"])),history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"LSTM Training\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
